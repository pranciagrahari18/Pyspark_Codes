{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11531195-5a40-462e-888d-a310a39bf7fe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# when() & otherwise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e4801b7-1805-435b-90ed-37dc19ab20d0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+------+\n| id|  name|gender|salary|\n+---+------+------+------+\n|  1|Pranci|     M|  2000|\n|  2| Tanna|     F|  3000|\n|  3|  abcd|      |  2000|\n+---+------+------+------+\n\n+---+------+------------------------------------------------------------------------------+\n| id|  name|CASE WHEN (gender = M) THEN Male WHEN (gender = F) THEN Female ELSE unkown END|\n+---+------+------------------------------------------------------------------------------+\n|  1|Pranci|                                                                          Male|\n|  2| Tanna|                                                                        Female|\n|  3|  abcd|                                                                        unkown|\n+---+------+------------------------------------------------------------------------------+\n\n+---+------+------+\n| id|  name|Gender|\n+---+------+------+\n|  1|Pranci|  Male|\n|  2| Tanna|Female|\n|  3|  abcd|unkown|\n+---+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when,col\n",
    "data = [(1,\"Pranci\",\"M\",2000),(2,\"Tanna\",\"F\",3000),(3,\"abcd\",\" \",2000)]\n",
    "schema = [\"id\",\"name\",\"gender\",\"salary\"]\n",
    "df = spark.createDataFrame(data,schema)\n",
    "df.show()\n",
    "df1 = df.select(df.id,df.name,when(df.gender == \"M\",\"Male\").when(df.gender == \"F\",\"Female\").otherwise(\"unkown\"))\n",
    "df1.show()\n",
    "df2 = df1.withColumnRenamed(\"CASE WHEN (gender = M) THEN Male WHEN (gender = F) THEN Female ELSE unkown END\",\"Gender\")\n",
    "df2.show()\n",
    "# It execute sequence of expression until it matches the conditions and returns a value whe match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0eb541ad-8da8-4aea-a137-8de2e5357796",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# alias(),asc(),desc(),cast() & like()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36779704-e18c-462d-a841-d006aa08ada3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+\n| id|    name|salary|\n+---+--------+------+\n|  1|  Pranci|  2000|\n|  2|   Tanna|  3000|\n|  3|Prashant|  2000|\n+---+--------+------+\n\n"
     ]
    }
   ],
   "source": [
    "data = [(1,\"Pranci\",2000),(2,\"Tanna\",3000),(3,\"Prashant\",2000)]\n",
    "schema = [\"id\",\"name\",\"salary\"]\n",
    "df = spark.createDataFrame(data,schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53cf3c56-2052-49f6-8287-9b371f93919f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+----------+\n|emp_id|emp_name|emp_salary|\n+------+--------+----------+\n|     1|  Pranci|      2000|\n|     2|   Tanna|      3000|\n|     3|Prashant|      2000|\n+------+--------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# ailas() - It is also used for rename the existing column and there is no diffrence between withColumnRenamed() and alias() but aials deal with sql commands data\n",
    "df1 = df.select(df.id.alias(\"emp_id\"),df.name.alias(\"emp_name\"),df.salary.alias(\"emp_salary\"))\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "781b95be-e7a1-4e05-982e-0bd56cbe3c81",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+\n| id|    name|salary|\n+---+--------+------+\n|  1|  Pranci|  2000|\n|  3|Prashant|  2000|\n|  2|   Tanna|  3000|\n+---+--------+------+\n\n+---+--------+------+\n| id|    name|salary|\n+---+--------+------+\n|  2|   Tanna|  3000|\n|  3|Prashant|  2000|\n|  1|  Pranci|  2000|\n+---+--------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# sort() - It is used to arange the data according to ascensing or decending order\n",
    "df.sort(df.name.asc()).show() # for ascending order and bydefault it will take ascending order\n",
    "df.sort(df.name.desc()).show() # for descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75dd1d35-11f6-4049-a2a9-ea15ed5ab047",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: long (nullable = true)\n |-- name: string (nullable = true)\n |-- salary: integer (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# cast() - It is used for casting the column according to requirement of a datatype \n",
    "df1 = df.select(df.id,df.name,df.salary.cast(\"int\"))\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a9fdc10-312e-4a09-a51f-cbb066b88dc4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+\n| id|    name|salary|\n+---+--------+------+\n|  1|  Pranci|  2000|\n|  3|Prashant|  2000|\n+---+--------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# like() - It is used to returns a boolean Column based on a LIKE match\n",
    "df1 = df.filter(df.name.like(\"P%\"))\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc99fbcd-6ccd-4a13-87fd-b493bc367d32",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#filter() and where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4c2645a-3a1e-41d9-be68-db81a3f8a379",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+------+\n| id|    name|gender|salary|\n+---+--------+------+------+\n|  1|  Pranci|Female|  2000|\n|  2|Prashant|  Male|  3000|\n|  3|   Tanna|Female|  2000|\n+---+--------+------+------+\n\n+---+--------+------+------+\n| id|    name|gender|salary|\n+---+--------+------+------+\n|  2|Prashant|  Male|  3000|\n+---+--------+------+------+\n\n+---+------+------+------+\n| id|  name|gender|salary|\n+---+------+------+------+\n|  1|Pranci|Female|  2000|\n|  3| Tanna|Female|  2000|\n+---+------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "data = [(1,\"Pranci\",\"Female\",2000),(2,\"Prashant\",\"Male\",3000),(3,\"Tanna\",\"Female\",2000)]\n",
    "schema = [\"id\",\"name\",\"gender\",\"salary\"]\n",
    "df = spark.createDataFrame(data,schema)\n",
    "df.show()\n",
    "df.filter(df.gender == \"Male\").show()\n",
    "df.filter(df.gender == \"Female\").show()\n",
    "# filter() and where() is used to to filter the rows from dataframe according to the requirement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12fc88da-2f95-479d-96f0-5ba5e8801360",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#distinct() & dropDuplicate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d9d5dc9-1e0f-4cbf-9b41-5a83c14c9c9f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+------+\n| id|  name|gender|salary|\n+---+------+------+------+\n|  1|Pranci|Female|  2000|\n|  1|Pranci|Female|  2000|\n|  3| Tanna|Female|  4000|\n+---+------+------+------+\n\n+---+------+------+------+\n| id|  name|gender|salary|\n+---+------+------+------+\n|  1|Pranci|Female|  2000|\n|  3| Tanna|Female|  4000|\n+---+------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# distinct() - It is used to select unique rows from all columns.\n",
    "data = [(1,\"Pranci\",\"Female\",2000),(1,\"Pranci\",\"Female\",2000),(3,\"Tanna\",\"Female\",4000)]\n",
    "schema = [\"id\",\"name\",\"gender\",\"salary\"]\n",
    "df = spark.createDataFrame(data,schema)\n",
    "df.show()\n",
    "df.distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90a31cc6-6bbc-4a27-97c0-a0ea985106b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+------+\n| id|  name|gender|salary|\n+---+------+------+------+\n|  1|Pranci|Female|  2000|\n|  3| Tanna|Female|  4000|\n+---+------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "#dropDuplicates() - It is used to delete duplicates rows from all columns.\n",
    "df.dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6c74dc4-315f-4a3f-a587-22610c810275",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+------+\n| id|    name|gender|salary|\n+---+--------+------+------+\n|  1|  Pranci|Female|  2000|\n|  1|  Pranci|Female|  2000|\n|  3|Prashant|  Male|  4000|\n+---+--------+------+------+\n\n+---+--------+------+------+\n| id|    name|gender|salary|\n+---+--------+------+------+\n|  1|  Pranci|Female|  2000|\n|  3|Prashant|  Male|  4000|\n+---+--------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# To delete duplicates row on the bases of conditions\n",
    "data = [(1,\"Pranci\",\"Female\",2000),(1,\"Pranci\",\"Female\",2000),(3,\"Prashant\",\"Male\",4000)]\n",
    "schema = [\"id\",\"name\",\"gender\",\"salary\"]\n",
    "df = spark.createDataFrame(data,schema)\n",
    "df.show()\n",
    "df.dropDuplicates([\"gender\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51ac1357-f576-4b4e-910c-195636ace867",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#orderBy() & sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d349288-dcbd-4ee6-93d2-c6210cca7b84",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---------+------+\n| id|    name|      dep|salary|\n+---+--------+---------+------+\n|  1|  Pranci|       IT|  2000|\n|  2|  Pranci|       HR|  2000|\n|  3|Prashant|Operation|  4000|\n+---+--------+---------+------+\n\n"
     ]
    }
   ],
   "source": [
    "data = [(1,\"Pranci\",\"IT\",2000),(2,\"Pranci\",\"HR\",2000),(3,\"Prashant\",\"Operation\",4000)]\n",
    "schema = [\"id\",\"name\",\"dep\",\"salary\"]\n",
    "df = spark.createDataFrame(data,schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed35649a-4ded-4d7c-9da6-765449652be9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---------------+------+\n| id|    name|            dep|salary|\n+---+--------+---------------+------+\n|  1|  Pranci|             IT|  2000|\n|  2|   Tanna|             IT|  3000|\n|  3|Prashant|Sales Marketing|  4000|\n|  4|    Basu|Sales Marketing|  4000|\n+---+--------+---------------+------+\n\n+---+--------+---------------+------+\n| id|    name|            dep|salary|\n+---+--------+---------------+------+\n|  1|  Pranci|             IT|  2000|\n|  2|   Tanna|             IT|  3000|\n|  3|Prashant|Sales Marketing|  4000|\n|  4|    Basu|Sales Marketing|  4000|\n+---+--------+---------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "#sort() - It is used to sort the column according to requirement\n",
    "df.sort(\"dep\").show()\n",
    "#or\n",
    "df.sort(df.dep).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "667e6ffe-c839-427d-9483-8ec9a31c8f0b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---------+------+\n| id|    name|      dep|salary|\n+---+--------+---------+------+\n|  2|  Pranci|       HR|  2000|\n|  1|  Pranci|       IT|  2000|\n|  3|Prashant|Operation|  4000|\n+---+--------+---------+------+\n\n+---+--------+---------+------+\n| id|    name|      dep|salary|\n+---+--------+---------+------+\n|  2|  Pranci|       HR|  2000|\n|  1|  Pranci|       IT|  2000|\n|  3|Prashant|Operation|  4000|\n+---+--------+---------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df.sort((df.dep),(df.id)).show()\n",
    "#or\n",
    "df.sort((df.dep),(df.id).desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d6e11e9-3ddf-4ae2-9c82-db11943f808f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#gropuBy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d30bd6e0-829d-4e3d-b64c-d8f5c00c9e2a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---------------+------+\n| id|    name|            dep|salary|\n+---+--------+---------------+------+\n|  1|  Pranci|             IT|  2000|\n|  2|   Tanna|             IT|  3000|\n|  3|Prashant|Sales Marketing|  4000|\n|  4|    Basu|Sales Marketing|  4000|\n+---+--------+---------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "data = [(1,\"Pranci\",\"IT\",2000),(2,\"Tanna\",\"IT\",3000),(3,\"Prashant\",\"Sales Marketing\",4000),(4,\"Basu\",\"Sales Marketing\",4000)]\n",
    "schema = [\"id\",\"name\",\"dep\",\"salary\"]\n",
    "df = spark.createDataFrame(data,schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09e058ee-7dc3-454d-8c5e-a5c2d2a1bfac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+\n|            dep|min(salary)|\n+---------------+-----------+\n|             IT|       2000|\n|Sales Marketing|       4000|\n+---------------+-----------+\n\n+---------------+-----------+\n|            dep|max(salary)|\n+---------------+-----------+\n|             IT|       3000|\n|Sales Marketing|       4000|\n+---------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# groupBy -It  is used to collect the identical data into groups and perform aggregate functions on the grouped data\n",
    "df1 = df.groupBy(\"dep\").min(\"salary\")\n",
    "df1.show()\n",
    "df2 = df.groupBy(\"dep\").max(\"salary\")\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59113ec4-8411-4c78-bc09-28c195e511c5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+-----+\n|            dep|salary|count|\n+---------------+------+-----+\n|             IT|  2000|    1|\n|             IT|  3000|    1|\n|Sales Marketing|  4000|    2|\n+---------------+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# use multiple column for groupBy condition\n",
    "df3 = df.groupBy(\"dep\",\"salary\").count()\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd29b7ff-6299-4155-83c5-fe87e24dd3bc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#groupBy().agg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3527ab2-81c1-475e-ae6b-1e9d332193be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---------------+------+\n| id|    name|            dep|salary|\n+---+--------+---------------+------+\n|  1|  Pranci|             IT|  2000|\n|  2|   Tanna|             IT|  3000|\n|  3|Prashant|Sales Marketing|  4000|\n|  4|    Basu|Sales Marketing|  4000|\n+---+--------+---------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "data = [(1,\"Pranci\",\"IT\",2000),(2,\"Tanna\",\"IT\",3000),(3,\"Prashant\",\"Sales Marketing\",4000),(4,\"Basu\",\"Sales Marketing\",4000)]\n",
    "schema = [\"id\",\"name\",\"dep\",\"salary\"]\n",
    "df = spark.createDataFrame(data,schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d01357e-3f3d-483f-9268-7be574366c3e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+\n|            dep|count of dep|\n+---------------+------------+\n|             IT|           2|\n|Sales Marketing|           2|\n+---------------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "df.groupBy(\"dep\").agg(count(\"*\").alias(\"count of dep\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f688fef3-f4a1-45b3-8c0c-0f457561eeec",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#UnionByName()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46f05051-7e89-452a-8f00-fb75fbbca66d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+------+\n| id|  name|gender|salary|\n+---+------+------+------+\n|  1|Pranci|     M|  2000|\n|  2| Tanna|     F|  3000|\n|  3|  abcd|      |  2000|\n|  5|  wxyz|      |  6000|\n+---+------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "#to merge/ union two Dataframe with a diffrent number of columns(diffrent schema)by passing allow missing column with the value true\n",
    "data = [(1,\"Pranci\",\"M\",2000),(2,\"Tanna\",\"F\",3000),(3,\"abcd\",\" \",2000),(5,\"wxyz\",\" \",6000)]\n",
    "schema = [\"id\",\"name\",\"gender\",\"salary\"]\n",
    "df1 = spark.createDataFrame(data,schema)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0bc4f18-cff3-4d96-9e1a-b23e7eca3e3c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---------------+------+\n| id|    name|            dep|salary|\n+---+--------+---------------+------+\n|  1|  Pranci|             IT|  2000|\n|  2|   Tanna|             IT|  3000|\n|  3|Prashant|Sales Marketing|  4000|\n|  4|    Basu|Sales Marketing|  4000|\n+---+--------+---------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "data = [(1,\"Pranci\",\"IT\",2000),(2,\"Tanna\",\"IT\",3000),(3,\"Prashant\",\"Sales Marketing\",4000),(4,\"Basu\",\"Sales Marketing\",4000)]\n",
    "schema = [\"id\",\"name\",\"dep\",\"salary\"]\n",
    "df2 = spark.createDataFrame(data,schema)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "023eb451-2157-48a4-867f-8f618228747d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+------+---------------+\n| id|    name|gender|salary|            dep|\n+---+--------+------+------+---------------+\n|  1|  Pranci|     M|  2000|           null|\n|  2|   Tanna|     F|  3000|           null|\n|  3|    abcd|      |  2000|           null|\n|  5|    wxyz|      |  6000|           null|\n|  1|  Pranci|  null|  2000|             IT|\n|  2|   Tanna|  null|  3000|             IT|\n|  3|Prashant|  null|  4000|Sales Marketing|\n|  4|    Basu|  null|  4000|Sales Marketing|\n+---+--------+------+------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "df1.unionByName(df2,allowMissingColumns=True).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfa89846-e282-44c0-b822-056f53847d63",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "905da212-0e8a-4628-807d-55edd58061b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---------------+------+\n| id|    name|            dep|salary|\n+---+--------+---------------+------+\n|  1|  Pranci|             IT|  2000|\n|  2|   Tanna|             IT|  3000|\n|  3|Prashant|Sales Marketing|  4000|\n|  4|    Basu|Sales Marketing|  4000|\n+---+--------+---------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "data = [(1,\"Pranci\",\"IT\",2000),(2,\"Tanna\",\"IT\",3000),(3,\"Prashant\",\"Sales Marketing\",4000),(4,\"Basu\",\"Sales Marketing\",4000)]\n",
    "schema = [\"id\",\"name\",\"dep\",\"salary\"]\n",
    "df = spark.createDataFrame(data,schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bac9ea1f-fb36-417e-be2c-7c93b69ca3e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n| id|    name|\n+---+--------+\n|  1|  Pranci|\n|  2|   Tanna|\n|  3|Prashant|\n|  4|    Basu|\n+---+--------+\n\n+---+--------+\n| id|    name|\n+---+--------+\n|  1|  Pranci|\n|  2|   Tanna|\n|  3|Prashant|\n|  4|    Basu|\n+---+--------+\n\n+---+---------------+\n| id|            dep|\n+---+---------------+\n|  1|             IT|\n|  2|             IT|\n|  3|Sales Marketing|\n|  4|Sales Marketing|\n+---+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.select(\"id\",\"name\").show()\n",
    "# or\n",
    "df.select(df.id,df.name).show()\n",
    "#or\n",
    "df.select(df[\"id\"],df[\"dep\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97cecf75-d75f-4ecb-aad0-8c0f5dfedf80",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n| id|salary|\n+---+------+\n|  1|  2000|\n|  2|  3000|\n|  3|  4000|\n|  4|  4000|\n+---+------+\n\n+---+--------+---------------+------+\n| id|    name|            dep|salary|\n+---+--------+---------------+------+\n|  1|  Pranci|             IT|  2000|\n|  2|   Tanna|             IT|  3000|\n|  3|Prashant|Sales Marketing|  4000|\n|  4|    Basu|Sales Marketing|  4000|\n+---+--------+---------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.select(col(\"id\"),col(\"salary\")).show()\n",
    "df.select(\"*\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63969c01-e119-45c2-8880-20dad2ea85da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---------------+------+\n| id|    name|            dep|salary|\n+---+--------+---------------+------+\n|  1|  Pranci|             IT|  2000|\n|  2|   Tanna|             IT|  3000|\n|  3|Prashant|Sales Marketing|  4000|\n|  4|    Basu|Sales Marketing|  4000|\n+---+--------+---------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df.select([col for col in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65913385-9f70-410f-afea-ed7fe7b874ad",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "687a8fd5-dec7-4951-854b-0c60f0a2ad4c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th></tr></thead><tbody><tr><td>36</td></tr><tr><td>39</td></tr><tr><td>42</td></tr><tr><td>46</td></tr><tr><td>72</td></tr><tr><td>85</td></tr><tr><td>88</td></tr><tr><td>100</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         36
        ],
        [
         39
        ],
        [
         42
        ],
        [
         46
        ],
        [
         72
        ],
        [
         85
        ],
        [
         88
        ],
        [
         100
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th></tr></thead><tbody><tr><td>1</td></tr><tr><td>4</td></tr><tr><td>5</td></tr><tr><td>6</td></tr><tr><td>7</td></tr><tr><td>9</td></tr><tr><td>10</td></tr><tr><td>11</td></tr><tr><td>12</td></tr><tr><td>13</td></tr><tr><td>15</td></tr><tr><td>17</td></tr><tr><td>20</td></tr><tr><td>21</td></tr><tr><td>22</td></tr><tr><td>23</td></tr><tr><td>24</td></tr><tr><td>26</td></tr><tr><td>31</td></tr><tr><td>34</td></tr><tr><td>35</td></tr><tr><td>36</td></tr><tr><td>38</td></tr><tr><td>40</td></tr><tr><td>41</td></tr><tr><td>46</td></tr><tr><td>47</td></tr><tr><td>48</td></tr><tr><td>49</td></tr><tr><td>51</td></tr><tr><td>52</td></tr><tr><td>53</td></tr><tr><td>54</td></tr><tr><td>55</td></tr><tr><td>61</td></tr><tr><td>64</td></tr><tr><td>65</td></tr><tr><td>67</td></tr><tr><td>71</td></tr><tr><td>76</td></tr><tr><td>78</td></tr><tr><td>79</td></tr><tr><td>80</td></tr><tr><td>81</td></tr><tr><td>82</td></tr><tr><td>83</td></tr><tr><td>84</td></tr><tr><td>85</td></tr><tr><td>87</td></tr><tr><td>88</td></tr><tr><td>89</td></tr><tr><td>90</td></tr><tr><td>91</td></tr><tr><td>93</td></tr><tr><td>95</td></tr><tr><td>97</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1
        ],
        [
         4
        ],
        [
         5
        ],
        [
         6
        ],
        [
         7
        ],
        [
         9
        ],
        [
         10
        ],
        [
         11
        ],
        [
         12
        ],
        [
         13
        ],
        [
         15
        ],
        [
         17
        ],
        [
         20
        ],
        [
         21
        ],
        [
         22
        ],
        [
         23
        ],
        [
         24
        ],
        [
         26
        ],
        [
         31
        ],
        [
         34
        ],
        [
         35
        ],
        [
         36
        ],
        [
         38
        ],
        [
         40
        ],
        [
         41
        ],
        [
         46
        ],
        [
         47
        ],
        [
         48
        ],
        [
         49
        ],
        [
         51
        ],
        [
         52
        ],
        [
         53
        ],
        [
         54
        ],
        [
         55
        ],
        [
         61
        ],
        [
         64
        ],
        [
         65
        ],
        [
         67
        ],
        [
         71
        ],
        [
         76
        ],
        [
         78
        ],
        [
         79
        ],
        [
         80
        ],
        [
         81
        ],
        [
         82
        ],
        [
         83
        ],
        [
         84
        ],
        [
         85
        ],
        [
         87
        ],
        [
         88
        ],
        [
         89
        ],
        [
         90
        ],
        [
         91
        ],
        [
         93
        ],
        [
         95
        ],
        [
         97
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to get the random sample subset from the large dataset\n",
    "df = spark.range(start = 1,end = 101)\n",
    "df1 = df.sample(fraction = 0.1,seed = 123)\n",
    "df2 = df.sample(fraction = 0.5,seed = 12)\n",
    "display(df1)\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9969670-224d-4c6f-a883-2da69af5bb16",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51bc7005-5734-471c-8bdc-b1df89ffd32c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+------+\n| id|  name|gender|salary|\n+---+------+------+------+\n|  1|Pranci|     M|  2000|\n|  2| Tanna|     F|  3000|\n|  3|  abcd|      |  2000|\n+---+------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "#collect() = It retrive all elements in a dataframe as an array of rows type to the driver node\n",
    "data = [(1,\"Pranci\",\"M\",2000),(2,\"Tanna\",\"F\",3000),(3,\"abcd\",\" \",2000)]\n",
    "schema = [\"id\",\"name\",\"gender\",\"salary\"]\n",
    "df = spark.createDataFrame(data,schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d60ed7b-bd8a-4a9a-9740-428d6fec7d87",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(id=1, name='Pranci', gender='M', salary=2000), Row(id=2, name='Tanna', gender='F', salary=3000), Row(id=3, name='abcd', gender=' ', salary=2000)]\nRow(id=1, name='Pranci', gender='M', salary=2000)\n3000\n"
     ]
    }
   ],
   "source": [
    "list = df.collect()\n",
    "print(list)\n",
    "print(list[0])\n",
    "print(list[1][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9a8fe20-e426-45dc-a6cf-0ec2586847a8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#pivot() & unpivot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f17bfeef-3127-4cfe-81bb-5d5ca015f14f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+------+\n|Customer_ID|Feedback_Category|Rating|\n+-----------+-----------------+------+\n|          1|          Quality|     4|\n|          1|          Service|     3|\n|          2|          Quality|     5|\n|          2|          Service|     4|\n|          3|          Quality|     2|\n|          3|          Service|     3|\n+-----------+-----------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# pivot() - It is used to rotate data in column into multiple columns\n",
    "data = [\n",
    "    (1, \"Quality\", 4),\n",
    "    (1, \"Service\", 3),\n",
    "    (2, \"Quality\", 5),\n",
    "    (2, \"Service\", 4),\n",
    "    (3, \"Quality\", 2),\n",
    "    (3, \"Service\", 3),\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data, [\"Customer_ID\", \"Feedback_Category\", \"Rating\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5832f089-b71d-4e3a-a34d-ff730ec32916",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------+\n|Customer_ID|Quality|Service|\n+-----------+-------+-------+\n|          1|    4.5|    3.5|\n|          3|    2.5|    2.5|\n|          2|    4.5|    4.5|\n+-----------+-------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "pivoted_df = df.groupBy(\"Customer_ID\").pivot(\"Feedback_Category\").agg(avg(\"Rating\"))\n",
    "pivoted_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec40666d-93e1-4b0d-bb91-ae47a3f2d048",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+------+\n|Customer_ID|Feedback_Category|Rating|\n+-----------+-----------------+------+\n|          1|          Quality|     4|\n|          1|          Service|     3|\n|          2|          Quality|     5|\n|          2|          Service|     4|\n|          3|          Quality|     2|\n|          3|          Service|     3|\n+-----------+-----------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "#unpivot() - It is rotating columns into rows\n",
    "unpivoted_df = pivoted_df.selectExpr(\"Customer_ID\", \"stack(2, 'Quality', Quality, 'Service', Service) as (Feedback_Category, Rating)\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14f75c79-c104-4823-a9b5-c6a655bcd2d8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#union() & unionAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f116f28-729a-4ccf-901f-1234aeaa727b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+------+\n| id|  name|gender|salary|\n+---+------+------+------+\n|  1|Pranci|     F|  2000|\n|  2| Tanna|     F|  3000|\n+---+------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "data = [(1,\"Pranci\",\"F\",2000),(2,\"Tanna\",\"F\",3000)]\n",
    "schema = [\"id\",\"name\",\"gender\",\"salary\"]\n",
    "df1 = spark.createDataFrame(data,schema)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "929107f3-8076-47e1-b041-da14814ff594",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+------+\n| id|  name|gender|salary|\n+---+------+------+------+\n|  1|Pranci|     F|  2000|\n|  2|  Basu|     M|  5000|\n+---+------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "data = [(1,\"Pranci\",\"F\",2000),(2,\"Basu\",\"M\",5000)]\n",
    "schema = [\"id\",\"name\",\"gender\",\"salary\"]\n",
    "df2 = spark.createDataFrame(data,schema)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fdc7de6-e317-458a-9ba8-c450666f7473",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+------+\n| id|  name|gender|salary|\n+---+------+------+------+\n|  1|Pranci|     F|  2000|\n|  2| Tanna|     F|  3000|\n|  1|Pranci|     F|  2000|\n|  2|  Basu|     M|  5000|\n+---+------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "newdf1 = df1.unionAll(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "667f295f-2574-4c83-bfa8-daaefa757864",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+------+\n| id|  name|gender|salary|\n+---+------+------+------+\n|  1|Pranci|     F|  2000|\n|  2| Tanna|     F|  3000|\n|  1|Pranci|     F|  2000|\n|  2|  Basu|     M|  5000|\n+---+------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "newdf2 = df1.union(df2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "afae3b4b-c7c9-446b-bb8c-b41f942ac187",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Convert RDD to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e42890b-54ea-4657-b819-716418040796",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'Pranci'), (2, 'Prashant')]\n"
     ]
    }
   ],
   "source": [
    "data = [(1,\"Pranci\"),(2,\"Prashant\")]\n",
    "rdd = spark.sparkContext.parallelize(data)\n",
    "print(rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "921656fc-6d2d-4ab1-a297-8475e375158d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n| _1|      _2|\n+---+--------+\n|  1|  Pranci|\n|  2|Prashant|\n+---+--------+\n\n+---+--------+\n| id|    name|\n+---+--------+\n|  1|  Pranci|\n|  2|Prashant|\n+---+--------+\n\n"
     ]
    }
   ],
   "source": [
    "df = rdd.toDF()\n",
    "df.show()\n",
    "#or\n",
    "df1 = spark.createDataFrame(rdd,schema=[\"id\",\"name\"])\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cec26022-2ace-4eb1-bf61-47c710b05d55",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6c5ac38-e69c-4f9b-80db-a421c19af272",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+\n| id|  name|salary|\n+---+------+------+\n|  1|Pranci|  8000|\n|  2|  Basu|  5000|\n+---+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "data = [(1,\"Pranci\",8000),(2,\"Basu\",5000)]\n",
    "schema = [\"id\",\"name\",\"salary\"]\n",
    "df = spark.createDataFrame(data,schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d93b232c-8847-430b-9a28-9b39f15ad9ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+\n| id|  name|salary|\n+---+------+------+\n|  1|PRANCI| 16000|\n|  2|  BASU| 10000|\n+---+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import upper\n",
    "def convertToUpper(df):\n",
    "    return df.withColumn(\"name\",upper(df.name))\n",
    "def doubleTheSalary(df):\n",
    "    return df.withColumn(\"salary\",(df.salary*2))\n",
    "df1 = df.transform(convertToUpper)\\\n",
    "    .transform(doubleTheSalary)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d02647ae-2631-42f4-9984-a907e34a6543",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Python_Advance_Functions",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
