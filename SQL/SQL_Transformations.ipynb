{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "733eb981-42ef-4022-aa88-3968b3ee1865",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#pyspark.sql.functions.transfrom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b763aaf-1730-4990-ad08-1b0fc2a5f977",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----------------+\n| id|  name|           skills|\n+---+------+-----------------+\n|  1|Pranci| [Pyspark, Azure]|\n|  2| Tanna|[Bigdata, Python]|\n+---+------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# It is used to apply the transformation on a column of type array and return an object of ArrayType.\n",
    "data = [(1,\"Pranci\",[\"Pyspark\",\"Azure\"]),(2,\"Tanna\",[\"Bigdata\",\"Python\"])]\n",
    "schema = [\"id\",\"name\",\"skills\"]\n",
    "df = spark.createDataFrame(data,schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf7df6b3-9698-4b4b-8795-c4e4ea3b0e59",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----------------+\n| id|  name|           skills|\n+---+------+-----------------+\n|  1|Pranci| [PYSPARK, AZURE]|\n|  2| Tanna|[BIGDATA, PYTHON]|\n+---+------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import transform,upper,col\n",
    "df1 = df.select(\"id\",\"name\",transform(\"skills\",lambda x: upper(x)).alias(\"skills\"))\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f943aa08-eb29-4da2-8ffb-fb38287db21e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------+\n|transform(skills, lambdafunction(upper(namedlambdavariable()), namedlambdavariable()))|\n+--------------------------------------------------------------------------------------+\n|                                                                      [PYSPARK, AZURE]|\n|                                                                     [BIGDATA, PYTHON]|\n+--------------------------------------------------------------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "def convertToUpper(x):\n",
    "    return upper(x)\n",
    "df1.select(transform(\"skills\",convertToUpper)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0fb31afb-0cb3-4f6f-a867-2f9aa28760b7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# createOrReplaceTempView()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b003c1e-c6aa-4005-9414-3f5d88af57b5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----------------+\n| id|  name|           skills|\n+---+------+-----------------+\n|  1|Pranci| [Pyspark, Azure]|\n|  2| Tanna|[Bigdata, Python]|\n+---+------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# By using this we can deal with SQL along with DataFrame\n",
    "# We can create temporary view on DataFrame by using createOrReplaceTempView() \n",
    "data = [(1,\"Pranci\",[\"Pyspark\",\"Azure\"]),(2,\"Tanna\",[\"Bigdata\",\"Python\"])]\n",
    "schema = [\"id\",\"name\",\"skills\"]\n",
    "df = spark.createDataFrame(data,schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fcd62ec-39e0-4947-bca7-cee61c8d30ad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----------------+\n| id|  name|           skills|\n+---+------+-----------------+\n|  1|Pranci| [Pyspark, Azure]|\n|  2| Tanna|[Bigdata, Python]|\n+---+------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"employees\")\n",
    "df1 = spark.sql(\"select * from employees\")\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0803b853-5289-4d83-bb65-069f2cae9dde",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>upper(name)</th></tr></thead><tbody><tr><td>1</td><td>PRANCI</td></tr><tr><td>2</td><td>TANNA</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "PRANCI"
        ],
        [
         2,
         "TANNA"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"long\""
        },
        {
         "metadata": "{\"__autoGeneratedAlias\":\"true\"}",
         "name": "upper(name)",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select id,upper(name) from employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96486ea5-857c-4c38-9cfe-273079d9b9ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1767635763084366,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "SQL_Transformations",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
